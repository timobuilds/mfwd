---
description: Information into tokens.
---

# Tokenization

Tokenization is the process of breaking down a sequence of text into chunks. Every word, prefix, suffix, and punctuation signs, and sends them into a token.



<figure><img src="../../../.gitbook/assets/tokenization.png" alt=""><figcaption><p>For example, if the sentence is “Write a story”, then the 4 corresponding tokens will be , , , and &#x3C;.>.</p></figcaption></figure>
