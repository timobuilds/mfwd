# How Transformers Enhance World Models?

**Attention = Understanding Relationships**

Transformers excel at world modeling because attention mechanisms naturally capture:

* **Spatial relationships:** "The castle is on top of the hill"
* **Semantic associations:** "Medieval villages have taverns and blacksmiths"
* **Functional constraints:** "Paths connect buildings"
* **Style consistency:** "All objects share the same artistic theme"

<br>
